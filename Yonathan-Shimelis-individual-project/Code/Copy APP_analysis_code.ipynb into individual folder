{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exploring American Presidency Project Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "\n",
    "os.chdir(r\"C:\\Users\\shime\\OneDrive\\Documents\\GitHub\\Final-Project-GroupJavaWockeez\\Code\")\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### We scraped the data using the following scraper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_URL = \"https://www.presidency.ucsb.edu\"\n",
    "LIST_PATH = \"/documents/app-categories/statements\"\n",
    "LIST_URL = BASE_URL + LIST_PATH\n",
    "OUTFILE = \"presidential_statements.csv\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; Scraper/1.0)\"}\n",
    "TEMP_SAVE_EVERY = 100   # flush every N records\n",
    "DELAY_BETWEEN_REQUESTS = 0.35\n",
    "\n",
    "def fetch(url, timeout=15, tries=3):\n",
    "    for attempt in range(tries):\n",
    "        try:\n",
    "            resp = requests.get(url, headers=HEADERS, timeout=timeout)\n",
    "            resp.raise_for_status()\n",
    "            return resp\n",
    "        except Exception as e:\n",
    "            print(f\"Fetch error ({attempt+1}/{tries}) for {url}: {e}\")\n",
    "            time.sleep(1)\n",
    "    return None\n",
    "\n",
    "def extract_detail_content(detail_url):\n",
    "    r = fetch(detail_url)\n",
    "    if not r:\n",
    "        return \"\", \"\", \"\"\n",
    "    s = BeautifulSoup(r.text, \"html.parser\")\n",
    "    content_node = s.select_one(\"div.field-docs-content\")\n",
    "    content = content_node.get_text(\"\\n\", strip=True) if content_node else \"\"\n",
    "\n",
    "    # categories (if present)\n",
    "    cats = s.select(\"div.group-meta a, div.field-ds-filed-under- a, .field-ds-filed-under a\")\n",
    "    categories = \", \".join([c.get_text(strip=True) for c in cats]) if cats else \"\"\n",
    "\n",
    "    # citation\n",
    "    cit = s.select_one(\".field-prez-document-citation, .ucsbapp_citation\")\n",
    "    citation = cit.get_text(\" \", strip=True) if cit else \"\"\n",
    "\n",
    "    return content, categories, citation\n",
    "\n",
    "def read_existing_urls(outfile):\n",
    "    p = Path(outfile)\n",
    "    if not p.exists():\n",
    "        return set()\n",
    "    try:\n",
    "        with p.open(\"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            return {row.get(\"url\",\"\").strip() for row in reader if row.get(\"url\")}\n",
    "    except Exception as e:\n",
    "        print(\"Error reading existing CSV, will start fresh:\", e)\n",
    "        return set()\n",
    "\n",
    "def scrape_statements(max_pages=None):\n",
    "    existing_urls = read_existing_urls(OUTFILE)\n",
    "    page = 0\n",
    "    total_saved = 0\n",
    "\n",
    "    # prepare CSV writer (append mode)\n",
    "    headers = [\"title\", \"url\", \"president\", \"date\", \"content\", \"categories\", \"citation\"]\n",
    "    outfile_path = Path(OUTFILE)\n",
    "    write_header = not outfile_path.exists()\n",
    "\n",
    "    csvfile = open(outfile_path, \"a\", newline=\"\", encoding=\"utf-8\")\n",
    "    writer = csv.DictWriter(csvfile, \n",
    "                            fieldnames=headers,\n",
    "                            quoting = csv.QUOTE_ALL,\n",
    "                            escapechar='\\\\')\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            if max_pages is not None and page >= max_pages:\n",
    "                print(\"Reached max_pages limit, stopping.\")\n",
    "                break\n",
    "\n",
    "            page_url = f\"{LIST_URL}?page={page}\"\n",
    "            resp = fetch(page_url)\n",
    "            if not resp:\n",
    "                print(\"Failed to fetch listing page:\", page_url)\n",
    "                break\n",
    "\n",
    "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "            # listing item containers for statements\n",
    "            items = soup.select(\"div.views-row, div.node-teaser, div.node-documents.node-teaser\")\n",
    "            # filter duplicates and ensure items have a link\n",
    "            items = [it for it in items if it.select_one(\"a[href*='/documents/']\")]\n",
    "\n",
    "            if not items:\n",
    "                print(f\"No items found on page {page}. Stopping.\")\n",
    "                break\n",
    "\n",
    "            num_items = len(items)\n",
    "            print(f\"Scraping page {page+1}: {num_items} statements (Total so far: {total_saved + num_items})\")\n",
    "\n",
    "            for item in items:\n",
    "                # Title + link\n",
    "                title_a = item.select_one(\".field-title a, h3 a, a[href*='/documents/']\")\n",
    "                if not title_a:\n",
    "                    print(\"Skipping item (no title link). snippet:\", item.get_text(\" \", strip=True)[:150])\n",
    "                    continue\n",
    "                title = title_a.get_text(strip=True)\n",
    "                href = title_a.get(\"href\", \"\").strip()\n",
    "                full_link = href if href.startswith(\"http\") else BASE_URL + href\n",
    "\n",
    "                # skip if already scraped\n",
    "                if full_link in existing_urls:\n",
    "                    # print(\"Skipping already-saved:\", full_link)\n",
    "                    continue\n",
    "\n",
    "                # president (the \"Related\" link on the right column)\n",
    "                pres_a = item.select_one(\".col-sm-4 a, .views-field-field-president a, .field-title ~ .col-sm-4 a\")\n",
    "                president = pres_a.get_text(strip=True) if pres_a else \"\"\n",
    "\n",
    "                # date\n",
    "                date_span = item.select_one(\"span.date-display-single, .views-field-field-docs-date span, .views-field-created span\")\n",
    "                date = date_span.get(\"content\", date_span.get_text(strip=True)) if date_span else \"\"\n",
    "\n",
    "                # fetch detail content\n",
    "                content, categories, citation = extract_detail_content(full_link)\n",
    "\n",
    "                row = {\n",
    "                    \"title\": title,\n",
    "                    \"url\": full_link,\n",
    "                    \"president\": president,\n",
    "                    \"date\": date,\n",
    "                    \"content\": content,\n",
    "                    \"categories\": categories,\n",
    "                    \"citation\": citation\n",
    "                }\n",
    "\n",
    "                writer.writerow(row)\n",
    "                existing_urls.add(full_link)\n",
    "                total_saved += 1\n",
    "\n",
    "                if total_saved % TEMP_SAVE_EVERY == 0:\n",
    "                    csvfile.flush()\n",
    "                    print(f\"Checkpoint: saved {total_saved} records so far.\")\n",
    "\n",
    "                time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "            page += 1\n",
    "            # small delay between pages\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    finally:\n",
    "        csvfile.close()\n",
    "\n",
    "    print(\"Finished. Total new records saved:\", total_saved)\n",
    "    return total_saved\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For a quick test set max_pages=2\n",
    "    # For full run use max_pages=None\n",
    "    scrape_statements(max_pages=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original scraper had issues with formatting columns, so we reformat here\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_final = pd.read_csv(\"presidential_statements.csv\", header=None)\n",
    "\n",
    "df_final.columns = [\n",
    "    \"title\",\n",
    "    \"url\",\n",
    "    \"president\",\n",
    "    \"date\",\n",
    "    \"content\",\n",
    "    \"categories\",\n",
    "    \"citation\"\n",
    "]\n",
    "\n",
    "df_final.to_csv(\"presidential_statements_scraped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# From here below I'm working on the American Presidency presidential statements csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the CSV file\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"presidential_statements_scraped.csv\")\n",
    "\n",
    "#Inspect the dataset\n",
    "print(dataset.shape)\n",
    "\n",
    "#Print the first few rows\n",
    "print(dataset.head())\n",
    "\n",
    "#Check columns\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Adding features for future visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add party affiliation based on president name\n",
    "#Make copy of df to keep original intact\n",
    "dataset_raw = dataset.copy()\n",
    "\n",
    "'''From this point on we will manipulate dataset and keep dataset_raw as original'''\n",
    "\n",
    "\n",
    "#Check dataset again\n",
    "print(dataset.columns)\n",
    "\n",
    "#Check presidents in dataset\n",
    "print(dataset['president'].unique())\n",
    "print(len(dataset['president'].unique()))\n",
    "\n",
    "#Add party affiliation\n",
    "party_affiliation = { \"Donald J. Trump (1st Term)\" : \"Republican\",\n",
    "                        \"Donald J. Trump (2nd Term)\" : \"Republican\",\n",
    "                        \"Joseph R. Biden, Jr.\": \"Democrat\",\n",
    "                        \"Barack Obama\": \"Democrat\",\n",
    "                        \"George W. Bush\": \"Republican\",\n",
    "                        \"William J. Clinton\": \"Democrat\",\n",
    "                        \"George Bush\": \"Republican\",\n",
    "                        \"Ronald Reagan\": \"Republican\",\n",
    "                        \"Jimmy Carter\": \"Democrat\",\n",
    "                        \"Gerald R. Ford\": \"Republican\",\n",
    "                        \"Richard Nixon\": \"Republican\",\n",
    "                        \"Lyndon B. Johnson\": \"Democrat\",\n",
    "                        \"John F. Kennedy\": \"Democrat\",\n",
    "                        \"Dwight D. Eisenhower\": \"Republican\",\n",
    "                        \"Harry S Truman\": \"Democrat\",\n",
    "                        \"Franklin D. Roosevelt\": \"Democrat\",\n",
    "                        \"Herbert Hoover\": \"Republican\", \n",
    "                        \"Calvin Coolidge\": \"Republican\",\n",
    "                        \"Warren G. Harding\": \"Republican\",\n",
    "                        \"Woodrow Wilson\": \"Democrat\",\n",
    "                        \"William Howard Taft\": \"Republican\",\n",
    "                        \"Theodore Roosevelt\": \"Republican\",\n",
    "                        \"William McKinley\": \"Republican\",\n",
    "                        \"Grover Cleveland\": \"Democrat\",\n",
    "                        \"Benjamin Harrison\": \"Republican\",\n",
    "                        \"Chester A. Arthur\": \"Republican\",\n",
    "                        \"James A. Garfield\": \"Republican\",\n",
    "                        \"Rutherford B. Hayes\": \"Republican\",\n",
    "                        \"Ulysses S. Grant\": \"Republican\",\n",
    "                        \"Andrew Johnson\": \"Democrat\",\n",
    "                        \"Abraham Lincoln\": \"Republican\",\n",
    "                        \"James Buchanan\": \"Democrat\",\n",
    "                        \"Franklin Pierce\": \"Democrat\",\n",
    "                        \"Millard Fillmore\": \"Whig\",\n",
    "                        \"Zachary Taylor\": \"Whig\",\n",
    "                        \"James K. Polk\": \"Democrat\",\n",
    "                        \"John Tyler\": \"Whig\",\n",
    "                        \"William Harrison\": \"Whig\",\n",
    "                        \"Martin Van Buren\": \"Democrat\",\n",
    "                        \"Andrew Jackson\": \"Democrat\",\n",
    "                        \"John Quincy Adams\": \"National Republican\",\n",
    "                        \"James Monroe\": \"Democrat-Republican\",\n",
    "                        \"James Madison\": \"Democrat-Republican\",\n",
    "                        \"Thomas Jefferson\": \"Democrat-Republican\",\n",
    "                        \"John Adams\": \"Federalist\",\n",
    "                        \"George Washington\": \"Federalist\"\n",
    "                        }\n",
    "\n",
    "#Check if we have all presidents listed\n",
    "print(len(party_affiliation))\n",
    "\n",
    "#Map party affiliation to df\n",
    "dataset['party'] = dataset['president'].map(party_affiliation)\n",
    "\n",
    "#Check if it correctly mapped\n",
    "print(dataset[['president', 'party']].drop_duplicates().sort_values(by='president'))\n",
    "\n",
    "'''Prior to the two party system we know, there were other parties such as Whig, Federalist, National Republican, and Democrat-Republican. We will keep these as is for now.'''\n",
    "\n",
    "#Remove gavin newsom speeches if any since he is not a president\n",
    "dataset = dataset[dataset['president'] != 'Gavin Newsom']\n",
    "\n",
    "#Check dataset again to see if drop worked\n",
    "\"Gavin Newsom\" in dataset['president'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Dataset is inspected, now we can preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess text\n",
    "\n",
    "#Import necessary libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') # Download if needed\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt') #Download if needed\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet') #Download if needed\n",
    "\n",
    "#Define stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "#Create function to preprocess text\n",
    "def preprocess(text): \n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'&[a-z]+;', ' ', text)  # Remove HTML entities\n",
    "    text = re.sub(r\"[^a-z\\s']\", ' ', text)  # Remove punctuation and special characters\n",
    "    text = re.sub(r'\\s+', ' ',text).strip()  # Remove extra whitespace\n",
    "    text = re.sub (r'\\d+', '', text)  # Remove numbers\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [word for word in tokens if word not in stopwords]  # Remove stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
    "    return ' '.join(tokens)  # Join tokens back to string\n",
    "\n",
    "#Apply to text \n",
    "dataset['cleaned_content'] = dataset['content'].apply(preprocess)\n",
    "\n",
    "#Check df \n",
    "print(dataset[['content', 'cleaned_content']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling with LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#Make new stopword list due to overlap in previous runs\n",
    "stopwords = ['american', 'america', 'states', 'state', 'president']\n",
    "\n",
    "#Vectorize statements \n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words=stopwords, ngram_range=(1,3))\n",
    "X = vectorizer.fit_transform(dataset['cleaned_content'])\n",
    "\n",
    "#Extract the topics \n",
    "lda = LatentDirichletAllocation(n_components=7, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "#Function for displaying the topics\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\"|\".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "#Display topics\n",
    "no_top_words = 10\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "display_topics(lda, feature_names, no_top_words)\n",
    "\n",
    "#Topic coherence evaluation\n",
    "print(lda.perplexity(X))\n",
    "print(lda.score(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting topic modeling with Gensim LDA\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "#Prepare data for Gensim\n",
    "texts = [doc.split() for doc in dataset['cleaned_content']]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "#Build LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15, random_state=42)\n",
    "\n",
    "#Display topics\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "#Evaluate topic coherence\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherence Score: {coherence_lda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic modeling again this time with NMF\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Vectorize again using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(dataset['cleaned_content'])\n",
    "\n",
    "#Fit NMF\n",
    "nmf = NMF(n_components=5, random_state=42)\n",
    "nmf.fit(X_tfidf)\n",
    "\n",
    "#Display topics\n",
    "no_top_words = 10 \n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "display_topics(nmf, feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizations for topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Building labels for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Naturally, the dataset doesn't have sentiment labels for us to work with. For this reason it's best that we try and do zero-shot classification and validate the results with another model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized sentiment analysis with CardiffNLP politics model\n",
    "import re\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Model setup\n",
    "model_name = \"cardiffnlp/xlm-twitter-politics-sentiment\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Use fast tokenizer; align truncation/padding for batching\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "sentiment_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Lightweight tweet-style normalization expected by CardiffNLP models\n",
    "def normalize_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text\n",
    "    t = re.sub(r\"https?://\\S+\", \"<url>\", t)\n",
    "    t = re.sub(r\"www\\.\\S+\", \"<url>\", t)\n",
    "    t = re.sub(r\"@[A-Za-z0-9_]+\", \"<user>\", t)\n",
    "    t = re.sub(r\"#[A-Za-z0-9_]+\", \"<hashtag>\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# Prepare batched inputs\n",
    "texts = dataset['content'].fillna(\"\").map(normalize_text).tolist()\n",
    "\n",
    "# Choose batch size based on hardware\n",
    "batch_sz = 32 if device == -1 else 64  # CPU vs GPU\n",
    "\n",
    "# Batched inference with padding/truncation for throughput\n",
    "results = sentiment_classifier(\n",
    "    texts,\n",
    "    batch_size=batch_sz,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512  # shorter seq length speeds inference, adjust if needed\n",
    ")\n",
    "\n",
    "# Assign results back\n",
    "dataset['transformer_sentiment'] = [r['label'] for r in results]\n",
    "dataset['transformer_sentiment_score'] = [r['score'] for r in results]\n",
    "\n",
    "# Quick checks\n",
    "print(dataset[['transformer_sentiment']].value_counts().head())\n",
    "print(dataset[['content', 'transformer_sentiment', 'transformer_sentiment_score']].head())\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing another of the same pipeline but changing max length to 256 to observe any differences\n",
    "# Optimized sentiment analysis with CardiffNLP politics model\n",
    "import re\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Model setup\n",
    "model_name = \"cardiffnlp/xlm-twitter-politics-sentiment\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Use fast tokenizer; align truncation/padding for batching\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "sentiment_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Lightweight tweet-style normalization expected by CardiffNLP models\n",
    "def normalize_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = text\n",
    "    t = re.sub(r\"https?://\\S+\", \"<url>\", t)\n",
    "    t = re.sub(r\"www\\.\\S+\", \"<url>\", t)\n",
    "    t = re.sub(r\"@[A-Za-z0-9_]+\", \"<user>\", t)\n",
    "    t = re.sub(r\"#[A-Za-z0-9_]+\", \"<hashtag>\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# Prepare batched inputs\n",
    "texts = dataset['content'].fillna(\"\").map(normalize_text).tolist()\n",
    "\n",
    "# Choose batch size based on hardware\n",
    "batch_sz = 32 if device == -1 else 64  # CPU vs GPU\n",
    "\n",
    "# Batched inference with padding/truncation for throughput\n",
    "results = sentiment_classifier(\n",
    "    texts,\n",
    "    batch_size=batch_sz,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=256  # shorter seq length speeds inference, adjust if needed\n",
    ")\n",
    "\n",
    "# Assign results back\n",
    "dataset['transformer_sentiment_256'] = [r['label'] for r in results]\n",
    "dataset['transformer_sentiment_score_256'] = [r['score'] for r in results]\n",
    "\n",
    "# Quick checks\n",
    "print(dataset[['transformer_sentiment_256']].value_counts().head())\n",
    "print(dataset[['content', 'transformer_sentiment_256', 'transformer_sentiment_score_256']].head())\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking a sample for inspection and comparing both max length results\n",
    "\n",
    "\n",
    "sample_df = dataset.sample(n=20, random_state=42)\n",
    "\n",
    "\n",
    "print(sample_df[['content', 'transformer_sentiment', 'transformer_sentiment_score', 'transformer_sentiment_256', 'transformer_sentiment_score_256']])\n",
    "\n",
    "\n",
    "#Check for differences between the two max lengths\n",
    "\n",
    "\n",
    "differences = dataset[dataset['transformer_sentiment'] != dataset['transformer_sentiment_256']]\n",
    "\n",
    "\n",
    "print(f\"Number of differences between max_length 512 and 256: {differences.shape[0]}\")\n",
    "\n",
    "print(differences[['content', 'transformer_sentiment', 'transformer_sentiment_score', 'transformer_sentiment_256', 'transformer_sentiment_score_256']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "We can observe a lot of flips by changing the max length to a longer max length of 512. We observe 1404 observations flip in the labeling. I think this more accurately captures the nature of political language and nuance in the language. Therefore, I will use the amx length of 512 moving forward in the project. It's also interesting to see some of the flips in index 46, 66, 12361, 12363, and more since the model did flip when having a longer max length, but the confidence or sentiment score dropped significantly lower. This could be a limitation in the dataset and modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### For a more technical analysis, we want to attempt to capture rhetoric more deeply. For this we will use another transformer this time, creating our own custom labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized zero-shot rhetoric classification with Tone, Strategy, Emotion\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Setup device for GPU acceleration if available\n",
    "\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize classifier (BART MNLI)\n",
    "\n",
    "\n",
    "clf = pipeline(\n",
    "\n",
    "    \"zero-shot-classification\",\n",
    "\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "\n",
    "    device=device\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Candidate labels\n",
    "\n",
    "\n",
    "tone_labels = [\"combative\", \"conciliatory\", \"neutral-ceremonial\"]  # exclusive choice\n",
    "\n",
    "strategy_labels = [\n",
    "\n",
    "    \"blame-assignment\", \"credit-claiming\", \"call-to-action\", \"reassurance\",\n",
    "\n",
    "    \"commemoration-condolence\", \"policy-detail\", \"patriotic-appeal\",\n",
    "\n",
    "    \"religious-appeal\", \"populist-anti-elite\", \"law-and-order\", \"other\"\n",
    "\n",
    "]  # multi-label\n",
    "\n",
    "emotion_labels = [\"anger\", \"fear\", \"hope\", \"pride\", \"sadness\", \"trust\"]  # multi-label\n",
    "\n",
    "\n",
    "\n",
    "# Prepare inputs\n",
    "\n",
    "\n",
    "texts = dataset['content'].fillna(\"\").tolist()\n",
    "\n",
    "batch_sz = 16 if device == -1 else 32\n",
    "\n",
    "\n",
    "\n",
    "# Helper to pick tone with a confidence margin so we can mark unclear cases as \"mixed\"\n",
    "\n",
    "\n",
    "def pick_with_margin(result, margin: float = 0.05):\n",
    "\n",
    "    scores = result[\"scores\"]\n",
    "\n",
    "    labels = result[\"labels\"]\n",
    "\n",
    "    if len(scores) < 2:\n",
    "\n",
    "        return labels[0]\n",
    "\n",
    "    if scores[0] - scores[1] >= margin:\n",
    "\n",
    "        return labels[0]\n",
    "\n",
    "    return \"mixed\"\n",
    "\n",
    "\n",
    "\n",
    "# 1) Tone (exclusive)\n",
    "\n",
    "\n",
    "tone_results = clf(\n",
    "\n",
    "    texts,\n",
    "\n",
    "    candidate_labels=tone_labels,\n",
    "\n",
    "    hypothesis_template=\"The statement uses {} rhetoric.\",\n",
    "\n",
    "    multi_label=False,\n",
    "\n",
    "    batch_size=batch_sz\n",
    "\n",
    ")\n",
    "\n",
    "dataset[\"tone\"] = [pick_with_margin(r, margin=0.05) for r in tone_results]\n",
    "\n",
    "\n",
    "\n",
    "# 2) Strategy (multi-label)\n",
    "\n",
    "\n",
    "strategy_results = clf(\n",
    "\n",
    "    texts,\n",
    "\n",
    "    candidate_labels=strategy_labels,\n",
    "\n",
    "    hypothesis_template=\"The statement uses {} rhetoric.\",\n",
    "\n",
    "    multi_label=True,\n",
    "\n",
    "    batch_size=batch_sz\n",
    "\n",
    ")\n",
    "\n",
    "thr_strategy = 0.35  # adjust between ~0.30-0.45 if needed\n",
    "\n",
    "dataset[\"strategies\"] = [\n",
    "\n",
    "    [lab for lab, sc in zip(r[\"labels\"], r[\"scores\"]) if sc >= thr_strategy] or [\"other\"]\n",
    "\n",
    "    for r in strategy_results\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# 3) Emotion (multi-label)\n",
    "\n",
    "\n",
    "emotion_results = clf(\n",
    "\n",
    "    texts,\n",
    "\n",
    "    candidate_labels=emotion_labels,\n",
    "\n",
    "    hypothesis_template=\"The statement expresses {}.\",\n",
    "\n",
    "    multi_label=True,\n",
    "\n",
    "    batch_size=batch_sz\n",
    "\n",
    ")\n",
    "\n",
    "thr_emotion = 0.30\n",
    "\n",
    "dataset[\"emotions\"] = [\n",
    "\n",
    "    [lab for lab, sc in zip(r[\"labels\"], r[\"scores\"]) if sc >= thr_emotion]\n",
    "\n",
    "    for r in emotion_results\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Quick sanity checks and distributions\n",
    "\n",
    "\n",
    "print(\"Tone distribution:\\n\", dataset[\"tone\"].value_counts())\n",
    "\n",
    "print(\"\\nTop strategies:\\n\", dataset[\"strategies\"].explode().value_counts().head(12))\n",
    "\n",
    "print(\"\\nTop emotions:\\n\", dataset[\"emotions\"].explode().value_counts().head(12))\n",
    "\n",
    "print(\"\\nSample rows:\\n\", dataset[[\"content\", \"tone\", \"strategies\", \"emotions\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement BOW and Logistic Regression Baseline for sentiment analysis\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Dataset view\n",
    "print(dataset.columns)\n",
    "print(dataset.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
